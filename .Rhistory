) %>%
unlist() %>%
unique() %>%
sort()
marked_biphone.list <-
lapply(biphone.list,mark_nonlexical) %>%
unlist()
phoneme.list <-
lapply(
X = biphone.list,
FUN = phoneme_constituents
) %>%
unlist() %>%
unlist() %>%
unique() %>%
sort()
marked_phoneme.list <-
lapply(phoneme.list,mark_nonlexical) %>%
unlist()
lexicon.dt <- data.table(list_chunk = word.list)
lexicon.dt[,constituents:= lapply(X = word.list, FUN = marked_constituents)]
sublexicon.dt <- data.table(list_chunk = c(marked_biphone.list,marked_phoneme.list))
sublexicon.dt[,constituents:= c(
lapply(
FUN=marked_phonemes,
X=biphone.list
),
rep(NA,length(phoneme.list))
)]
mfield.dt <- rbind(
lexicon.dt,
sublexicon.dt
)
mfield.dt
edge_set_vertical <- mfield.dt %>%
unnest(cols = constituents) %>%
drop_na %>%
data.table
edge_set_vertical
mfield.g <- graph_from_data_frame(
vertices = mfield.dt$list_chunk,
d = edge_set_vertical,
directed = TRUE
)
mfield.g %>%
plot()
#WORKING MEMORY (input) set
wm_vset <- data.frame(
v = c(
mark_input(phoneme.list)
),
type = c(
rep("INPUT")
),
length = c(
rep(1)
)
)
input_vector <- strsplit(input_word,"") %>% unlist()
dataset<-data.frame(input= input_vector)
dt <- data.table( dataset )
dt$Index <- 1:nrow(dt)
#dt[ , Index := rep(1) , by = c("input") ]
dt$v <- paste(dt$input,dt$Index, sep = "")
#dt <- class(as.data.frame(dt))
setDF(dt)
wm_vset <- dt
wm_vset$type = 'INPUT'
wm_vset$length = 1
wm_vset$Index = NULL
wm_vset$input = NULL
wm_vset$v <- lapply(wm_vset[,'v'], function(x) mark_input(x))
#vset$y[vset$type=='INPUT'] <- 0
#vset$y[vset$type=='FALSE'  & vset$length==1] <- 4
#vset$y[vset$type=='FALSE'  & vset$length==2] <- 6
#vset$y[vset$type=='TRUE'] <- 10
#vset$x <- 1:nrow(vset)
#vset$x[vset$type=='INPUT'] <- 1:nrow(vset)
#vset$x[vset$type=='FALSE'& vset$length==1] <- 1:999
#vset$x[vset$type=='FALSE'& vset$length==2] <- 1:999
#vset$x[vset$type=='TRUE'] <- 1:nrow(vset)
#SHORT-TERM MEMORY nodes
stm_vset <- data.frame(
v = c(
word.list,
paste0('.',biphone.list),
paste0('.',phoneme.list)
),
type = c(
rep(TRUE,length(word.list)),
rep(FALSE,length(biphone.list)),
rep(FALSE,length(phoneme.list))
),
length = c(
nchar(word.list),
nchar(biphone.list),
nchar(phoneme.list)
)
)
#ALL VERTICIES (input) set
vset <- rbind(wm_vset, stm_vset)
#generate MASKING edge set
eset1 <- lexicon.dt[,
list(
v1 = rep(word,lengths(constituents)),
v2 = unlist(constituents)
)
]
mfield.g %>%
plot(layout.bipartite())
mfield.g %>%
plot(layout.circle(mfield.g))
mfield.g %>%
plot()
View(eset1)
View(eset1)
View(eset2)
library(data.table)
library(tidyr)
library(igraph)
library(ggplot2)
library(stringr)
require(data.table)
data <- 'artful_toy_net.csv' # is it artful? paper
#data <- 'pu.csv'
input_word <- 'bin'
sample_size <- 4
all_substr <- # Returns a vector of all substrings of length n from x
function(x, n) substring(
text = x,
first = 1:(nchar(x) - n + 1),
last = n:nchar(x)
)
unique_substr <- # Returns a vector of all unique substrings of length n from x
function(x, n) all_substr(x = x, n = n) %>%
unique()
ordered_phoneme_constituents <- # Returns all the "1grams," i.e. one-length kgrams
function(x) unique_substr(x = x, n = 1)[nchar(all_substr(x,1)) == 1]
phoneme_constituents <- # Returns all the "1grams," i.e. one-length kgrams
function(x) unique_substr(x = x, n = 1)[nchar(unique_substr(x,1)) == 1]
biphone_constituents <- # Returns all the "2grams," i.e. two-length kgrams
function(x) unique_substr(x = x, n = 2)[nchar(unique_substr(x,2)) == 2]
listchunk_constituents <- # Returns both biphones and phonemes
function(x) union(
phoneme_constituents(x),
biphone_constituents(x)
)
mark_input <-
function(x) paste0('$',x)
mark_nonlexical <- # Returns listchunk_constituents marked for nonlexicality
function(x) paste0('.',x)
marked_biphones <-
function(x) biphone_constituents(x) %>%
lapply(FUN = mark_nonlexical) %>%
unlist()
marked_phonemes <-
function(x) phoneme_constituents(x) %>%
lapply(FUN = mark_nonlexical) %>%
unlist()
marked_constituents <- # Returns both biphones and phonemes
function(x) union(
marked_phonemes(x),
marked_biphones(x)
)
word.list <- fread(file=data)$Klattese
word.list <- word.list[1:sample_size]
biphone.list <-
lapply(
X = word.list,
FUN = biphone_constituents
) %>%
unlist() %>%
unique() %>%
sort()
marked_biphone.list <-
lapply(biphone.list,mark_nonlexical) %>%
unlist()
phoneme.list <-
lapply(
X = biphone.list,
FUN = phoneme_constituents
) %>%
unlist() %>%
unlist() %>%
unique() %>%
sort()
marked_phoneme.list <-
lapply(phoneme.list,mark_nonlexical) %>%
unlist()
lexicon.dt <- data.table(list_chunk = word.list)
lexicon.dt[,constituents:= lapply(X = word.list, FUN = marked_constituents)]
sublexicon.dt <- data.table(list_chunk = c(marked_biphone.list,marked_phoneme.list))
sublexicon.dt[,constituents:= c(
lapply(
FUN=marked_phonemes,
X=biphone.list
),
rep(NA,length(phoneme.list))
)]
mfield.dt <- rbind(
lexicon.dt,
sublexicon.dt
)
mfield.dt
edge_set_vertical <- mfield.dt %>%
unnest(cols = constituents) %>%
drop_na %>%
data.table
edge_set_vertical
mfield.g <- graph_from_data_frame(
vertices = mfield.dt$list_chunk,
d = edge_set_vertical,
directed = TRUE
)
mfield.g %>%
plot()
#WORKING MEMORY (input) set
wm_vset <- data.frame(
v = c(
mark_input(phoneme.list)
),
type = c(
rep("INPUT")
),
length = c(
rep(1)
)
)
input_vector <- strsplit(input_word,"") %>% unlist()
dataset<-data.frame(input= input_vector)
dt <- data.table( dataset )
dt$Index <- 1:nrow(dt)
#dt[ , Index := rep(1) , by = c("input") ]
dt$v <- paste(dt$input,dt$Index, sep = "")
#dt <- class(as.data.frame(dt))
setDF(dt)
wm_vset <- dt
wm_vset$type = 'INPUT'
wm_vset$length = 1
wm_vset$Index = NULL
wm_vset$input = NULL
wm_vset$v <- lapply(wm_vset[,'v'], function(x) mark_input(x))
#vset$y[vset$type=='INPUT'] <- 0
#vset$y[vset$type=='FALSE'  & vset$length==1] <- 4
#vset$y[vset$type=='FALSE'  & vset$length==2] <- 6
#vset$y[vset$type=='TRUE'] <- 10
#vset$x <- 1:nrow(vset)
#vset$x[vset$type=='INPUT'] <- 1:nrow(vset)
#vset$x[vset$type=='FALSE'& vset$length==1] <- 1:999
#vset$x[vset$type=='FALSE'& vset$length==2] <- 1:999
#vset$x[vset$type=='TRUE'] <- 1:nrow(vset)
#SHORT-TERM MEMORY nodes
stm_vset <- data.frame(
v = c(
word.list,
paste0('.',biphone.list),
paste0('.',phoneme.list)
),
type = c(
rep(TRUE,length(word.list)),
rep(FALSE,length(biphone.list)),
rep(FALSE,length(phoneme.list))
),
length = c(
nchar(word.list),
nchar(biphone.list),
nchar(phoneme.list)
)
)
#ALL VERTICIES (input) set
vset <- rbind(wm_vset, stm_vset)
#generate MASKING edge set
eset1 <- lexicon.dt[,
list(
v1 = rep(word,lengths(constituents)),
v2 = unlist(constituents)
)
]
#generate MASKING edge set
eset1 <- lexicon.dt[,
list(
v1 = rep(list_chunk,lengths(constituents)),
v2 = unlist(constituents)
)
]
eset2 <- sublexicon.dt[,
list(
v1 = rep(mark_nonlexical(biphone),lengths(phonemes)),
v2 = unlist(phonemes)
)
]
#generate MASKING edge set
eset1 <- lexicon.dt[,
list(
v1 = rep(list_chunk,lengths(constituents)),
v2 = unlist(constituents)
)
]
eset2 <- sublexicon.dt[,
list(
v1 = rep(mark_nonlexical(list_chunk),lengths(phonemes)),
v2 = unlist(phonemes)
)
]
#generate MASKING edge set
eset1 <- lexicon.dt[,
list(
v1 = rep(list_chunk,lengths(constituents)),
v2 = unlist(constituents)
)
]
eset2 <- sublexicon.dt[,
list(
v1 = rep(mark_nonlexical(list_chunk),lengths(constituents)),
v2 = unlist(constituents)
)
]
mask_eset <- rbind(eset1,eset2)
mask_eset$type <- "masking"
library(data.table)
library(tidyr)
library(igraph)
library(ggplot2)
library(stringr)
require(data.table)
data <- 'artful_toy_net.csv' # is it artful? paper
#data <- 'pu.csv'
input_word <- 'bin'
sample_size <- 4
all_substr <- # Returns a vector of all substrings of length n from x
function(x, n) substring(
text = x,
first = 1:(nchar(x) - n + 1),
last = n:nchar(x)
)
unique_substr <- # Returns a vector of all unique substrings of length n from x
function(x, n) all_substr(x = x, n = n) %>%
unique()
ordered_phoneme_constituents <- # Returns all the "1grams," i.e. one-length kgrams
function(x) unique_substr(x = x, n = 1)[nchar(all_substr(x,1)) == 1]
phoneme_constituents <- # Returns all the "1grams," i.e. one-length kgrams
function(x) unique_substr(x = x, n = 1)[nchar(unique_substr(x,1)) == 1]
biphone_constituents <- # Returns all the "2grams," i.e. two-length kgrams
function(x) unique_substr(x = x, n = 2)[nchar(unique_substr(x,2)) == 2]
listchunk_constituents <- # Returns both biphones and phonemes
function(x) union(
phoneme_constituents(x),
biphone_constituents(x)
)
mark_input <-
function(x) paste0('$',x)
mark_nonlexical <- # Returns listchunk_constituents marked for nonlexicality
function(x) paste0('.',x)
marked_biphones <-
function(x) biphone_constituents(x) %>%
lapply(FUN = mark_nonlexical) %>%
unlist()
marked_phonemes <-
function(x) phoneme_constituents(x) %>%
lapply(FUN = mark_nonlexical) %>%
unlist()
marked_constituents <- # Returns both biphones and phonemes
function(x) union(
marked_phonemes(x),
marked_biphones(x)
)
word.list <- fread(file=data)$Klattese
word.list <- word.list[1:sample_size]
biphone.list <-
lapply(
X = word.list,
FUN = biphone_constituents
) %>%
unlist() %>%
unique() %>%
sort()
marked_biphone.list <-
lapply(biphone.list,mark_nonlexical) %>%
unlist()
phoneme.list <-
lapply(
X = biphone.list,
FUN = phoneme_constituents
) %>%
unlist() %>%
unlist() %>%
unique() %>%
sort()
marked_phoneme.list <-
lapply(phoneme.list,mark_nonlexical) %>%
unlist()
lexicon.dt <- data.table(list_chunk = word.list)
lexicon.dt[,constituents:= lapply(X = word.list, FUN = marked_constituents)]
sublexicon.dt <- data.table(list_chunk = c(marked_biphone.list,marked_phoneme.list))
sublexicon.dt[,constituents:= c(
lapply(
FUN=marked_phonemes,
X=biphone.list
),
rep(NA,length(phoneme.list))
)]
mfield.dt <- rbind(
lexicon.dt,
sublexicon.dt
)
mfield.dt
edge_set_vertical <- mfield.dt %>%
unnest(cols = constituents) %>%
drop_na %>%
data.table
edge_set_vertical
mfield.g <- graph_from_data_frame(
vertices = mfield.dt$list_chunk,
d = edge_set_vertical,
directed = TRUE
)
mfield.g %>%
plot()
#WORKING MEMORY (input) set
wm_vset <- data.frame(
v = c(
mark_input(phoneme.list)
),
type = c(
rep("INPUT")
),
length = c(
rep(1)
)
)
input_vector <- strsplit(input_word,"") %>% unlist()
dataset<-data.frame(input= input_vector)
dt <- data.table( dataset )
dt$Index <- 1:nrow(dt)
#dt[ , Index := rep(1) , by = c("input") ]
dt$v <- paste(dt$input,dt$Index, sep = "")
#dt <- class(as.data.frame(dt))
setDF(dt)
wm_vset <- dt
wm_vset$type = 'INPUT'
wm_vset$length = 1
wm_vset$Index = NULL
wm_vset$input = NULL
wm_vset$v <- lapply(wm_vset[,'v'], function(x) mark_input(x))
#vset$y[vset$type=='INPUT'] <- 0
#vset$y[vset$type=='FALSE'  & vset$length==1] <- 4
#vset$y[vset$type=='FALSE'  & vset$length==2] <- 6
#vset$y[vset$type=='TRUE'] <- 10
#vset$x <- 1:nrow(vset)
#vset$x[vset$type=='INPUT'] <- 1:nrow(vset)
#vset$x[vset$type=='FALSE'& vset$length==1] <- 1:999
#vset$x[vset$type=='FALSE'& vset$length==2] <- 1:999
#vset$x[vset$type=='TRUE'] <- 1:nrow(vset)
#SHORT-TERM MEMORY nodes
stm_vset <- data.frame(
v = c(
word.list,
paste0('.',biphone.list),
paste0('.',phoneme.list)
),
type = c(
rep(TRUE,length(word.list)),
rep(FALSE,length(biphone.list)),
rep(FALSE,length(phoneme.list))
),
length = c(
nchar(word.list),
nchar(biphone.list),
nchar(phoneme.list)
)
)
#ALL VERTICIES (input) set
vset <- rbind(wm_vset, stm_vset)
#generate MASKING edge set
eset1 <- lexicon.dt[,
list(
v1 = rep(list_chunk,lengths(constituents)),
v2 = unlist(constituents)
)
]
eset2 <- sublexicon.dt[,
list(
v1 = rep(mark_nonlexical(list_chunk),lengths(constituents)),
v2 = unlist(constituents)
)
]
mask_eset <- rbind(eset1,eset2)
mask_eset$type <- "masking"
#Generate INHIBITORY edges for lexical entries
eset3 <- lexicon.dt[,
list(
v1 = rep(lexicon.dt$word, lengths(lexicon.dt$biphones)),
v2 = unlist(lexicon.dt$biphones)
)
]
#create datatable where c1 is a biphone, c2 and c3 are words that share that biphone
eset3 <- unique(merge(eset3, eset3, by = "v2", allow.cartesian =TRUE))
#Generate INHIBITORY edges for lexical entries
eset3 <- lexicon.dt[,
list(
v1 = rep(lexicon.dt$item, lengths(lexicon.dt$constituents)),
v2 = unlist(lexicon.dt$constituents)
)
]
#create datatable where c1 is a biphone, c2 and c3 are words that share that biphone
eset3 <- unique(merge(eset3, eset3, by = "v2", allow.cartesian =TRUE))
#drop biphones column
eset3$v2 <- NULL
#drop "symmetrical" columns (where c1 == c2)
eset3 <- eset3[eset3$v1.x!=eset3$v1.y,]
#remove reverse duplicate columns
eset3 <- eset3[!duplicated(lapply(as.data.frame(t(eset3), stringsAsFactors=FALSE), sort)),]
